gpt4:
  model: gpt-4
  maxtokens: 8192
  provider: "ChatOpenAI(temperature=0, model_name='gpt-4')"
  active: 0
gpt4t:
  model: gpt-4-turbo
  maxtokens: 128000
  provider: "ChatOpenAI(temperature=0, model_name='gpt-4-turbo')"
  active: 1
gpt35t:
  model: gpt-3.5-turbo
  maxtokens: 16384
  provider: "ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
  active: 1
claude:
  model: claude-3-opus-20240229
  maxtokens: 200000
  provider: "ChatAnthropic(temperature=0, model_name='claude-3-opus-20240229')"
  active: 1
google:
  model: gemini-1.0-pro
  maxtokens: 999999
  provider: "ChatGoogleGenerativeAI(temperature=temperature,model='gemini-1.0-pro',convert_system_message_to_human=True,safety_settings={HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE})"
  active: 1
google15:
  model: gemini-1.5-pro-latest
  maxtokens: 999999
  provider: "ChatGoogleGenerativeAI(temperature=temperature,model='gemini-1.5-pro-latest',convert_system_message_to_human=True,safety_settings={HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE})"
  active: 1
mixtralfw:
  model: open-mixtral-8x7b
  maxtokens: 16384
  provider: "ChatFireworks(temperature=1, model_name='accounts/fireworks/models/mixtral-8x7b-instruct')"
  active: 1
llamafw:
  model: llama-v3-70b-instruct
  maxtokens: 65534
  provider: "ChatFireworks(temperature=0, model='accounts/fireworks/models/llama-v3-70b-instruct')"
  active: 1
mixtral:
  model: open-mixtral-8x7b
  maxtokens: 4096
  provider: "ChatGroq(temperature=0, model_name='mixtral-8x7b-32768')"
  active: 1
llama3:
  model: llama-v3-70b-instruct
  maxtokens: 4096
  provider: "ChatGroq(temperature=0, model='llama3-70b-8192')"
  active: 1